{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.50\n",
      "Predictions on inference data: [0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Generate synthetic dataset\n",
    "def create_dataset(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    data = pd.DataFrame({\n",
    "        'age': [25, np.nan, 28, 35, np.nan, 40],\n",
    "        'income': [50000, 60000, np.nan, 80000, 75000, np.nan],\n",
    "        'gender': ['male', 'female', 'female', 'male', np.nan, 'female'],\n",
    "        'target': [0, 1, 0, 1, 0, 1]\n",
    "    })\n",
    "    return data\n",
    "\n",
    "# Shared preprocessing pipeline\n",
    "def get_preprocessing_pipeline():\n",
    "    numeric_features = ['age', 'income']\n",
    "    categorical_features = ['gender']\n",
    "\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "# Train pipeline with model\n",
    "def train_pipeline(data):\n",
    "    X = data.drop(columns='target')\n",
    "    y = data['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    preprocessor = get_preprocessing_pipeline()\n",
    "    clf_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestClassifier(random_state=42))\n",
    "    ])\n",
    "\n",
    "    clf_pipeline.fit(X_train, y_train)\n",
    "    y_pred = clf_pipeline.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Training Accuracy: {acc:.2f}\")\n",
    "    return clf_pipeline\n",
    "\n",
    "# Save and load functions\n",
    "def save_model(model, path='model_pipeline.pkl'):\n",
    "    joblib.dump(model, path)\n",
    "\n",
    "def load_model(path='model_pipeline.pkl'):\n",
    "    return joblib.load(path)\n",
    "\n",
    "# Demonstration\n",
    "train_data = create_dataset()\n",
    "model_pipeline = train_pipeline(train_data)\n",
    "save_model(model_pipeline)\n",
    "\n",
    "# Simulate inference\n",
    "inference_data = create_dataset(seed=99).drop(columns='target')\n",
    "loaded_pipeline = load_model()\n",
    "predictions = loaded_pipeline.predict(inference_data)\n",
    "print(\"Predictions on inference data:\", predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
