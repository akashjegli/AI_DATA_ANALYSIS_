{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped due to high correlation: ['Longitude']\n",
      "Selected by MI: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "Selected by VarianceThreshold: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude', 'MedHouseVal']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# --- Load California housing dataset ---\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "df = housing.frame\n",
    "\n",
    "# --- Introduce missing values for demonstration ---\n",
    "df_missing = df.copy()\n",
    "df_missing.iloc[0:10, 0] = np.nan  # introduce NaNs in the first column\n",
    "df_missing.iloc[20:25, 5] = np.nan  # introduce NaNs in another column\n",
    "\n",
    "# --- Imputation: Mean ---\n",
    "try:\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    df_mean_imputed = pd.DataFrame(mean_imputer.fit_transform(df_missing), columns=df.columns)\n",
    "except Exception as e:\n",
    "    print(\"Mean imputation failed:\", e)\n",
    "\n",
    "# --- Imputation: Median ---\n",
    "try:\n",
    "    median_imputer = SimpleImputer(strategy='median')\n",
    "    df_median_imputed = pd.DataFrame(median_imputer.fit_transform(df_missing), columns=df.columns)\n",
    "except Exception as e:\n",
    "    print(\"Median imputation failed:\", e)\n",
    "\n",
    "# --- Imputation: KNN ---\n",
    "try:\n",
    "    knn_imputer = KNNImputer(n_neighbors=3)\n",
    "    df_knn_imputed = pd.DataFrame(knn_imputer.fit_transform(df_missing), columns=df.columns)\n",
    "except Exception as e:\n",
    "    print(\"KNN imputation failed:\", e)\n",
    "\n",
    "# --- Scaling ---\n",
    "scalers = {\n",
    "    \"StandardScaler\": StandardScaler(),\n",
    "    \"MinMaxScaler\": MinMaxScaler(),\n",
    "    \"RobustScaler\": RobustScaler()\n",
    "}\n",
    "scaled_dfs = {}\n",
    "for name, scaler in scalers.items():\n",
    "    try:\n",
    "        scaled_data = scaler.fit_transform(df.fillna(0))  # use original (non-missing) for scaling\n",
    "        scaled_dfs[name] = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "    except Exception as e:\n",
    "        print(f\"{name} failed:\", e)\n",
    "\n",
    "# --- Feature Selection: Correlation ---\n",
    "try:\n",
    "    corr_matrix = df.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "    df_uncorrelated = df.drop(columns=to_drop)\n",
    "    print(\"Dropped due to high correlation:\", to_drop)\n",
    "except Exception as e:\n",
    "    print(\"Correlation filtering failed:\", e)\n",
    "\n",
    "# --- Feature Selection: Mutual Information ---\n",
    "try:\n",
    "    X = df.drop(columns=[\"MedHouseVal\"])\n",
    "    y = df[\"MedHouseVal\"]\n",
    "    mi = mutual_info_regression(X.fillna(0), y)\n",
    "    mi_scores = pd.Series(mi, index=X.columns)\n",
    "    important_features = mi_scores[mi_scores > 0.01].index.tolist()\n",
    "    df_mi_selected = df[important_features + [\"MedHouseVal\"]]\n",
    "    print(\"Selected by MI:\", important_features)\n",
    "except Exception as e:\n",
    "    print(\"Mutual information selection failed:\", e)\n",
    "\n",
    "# --- Feature Selection: Variance Threshold ---\n",
    "try:\n",
    "    selector = VarianceThreshold(threshold=0.01)\n",
    "    df_variance_selected = selector.fit_transform(df.fillna(0))\n",
    "    selected_columns = df.columns[selector.get_support()]\n",
    "    df_var_selected = pd.DataFrame(df_variance_selected, columns=selected_columns)\n",
    "    print(\"Selected by VarianceThreshold:\", list(selected_columns))\n",
    "except Exception as e:\n",
    "    print(\"Variance threshold failed:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
