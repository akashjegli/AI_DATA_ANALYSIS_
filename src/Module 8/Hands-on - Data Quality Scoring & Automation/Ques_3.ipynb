{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate Data Quality Checks with Great Expectations\n",
    "**Introduction**: In this activity, you will learn how to automate data quality checks using the Great Expectations framework. This includes setting up expectations and generating validation reports.\n",
    "\n",
    "### Task 1: Setup and Initial Expectations\n",
    "\n",
    "1. Objective: Set up Great Expectations and create initial expectations for a dataset.\n",
    "2. Steps:\n",
    "    - Install Great Expectations using pip.\n",
    "    - Initialize a data context.\n",
    "    - Create basic expectations on a sample dataset.\n",
    "    - Eg., Implement a basic setup and expectation for column presence and type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'great_expectations.dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchRequest\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Step 1: Load Sample Data\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Replace this with your actual data path\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'great_expectations.dataset'"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "# Write your code from here\n",
    "# Importing necessary libraries\n",
    "import great_expectations as ge\n",
    "import pandas as pd\n",
    "from great_expectations.core.batch import BatchRequest\n",
    "from great_expectations.dataset import Dataset\n",
    "from great_expectations.data_context import DataContext\n",
    "\n",
    "# Step 1: Load Sample Data\n",
    "# Replace this with your actual data path\n",
    "df = pd.read_csv(\"sample_data.csv\")\n",
    "print(\"Sample Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Initialize Great Expectations Context (if not already initialized)\n",
    "# If this is your first time, initialize the data context with:\n",
    "# great_expectations init\n",
    "\n",
    "# Step 3: Setup DataContext\n",
    "context = DataContext()\n",
    "\n",
    "# Step 4: Add Data Source (if not already added through CLI)\n",
    "# You can add a datasource like this (this can also be done via CLI):\n",
    "# context.add_datasource(\n",
    "#     \"my_pandas_datasource\",\n",
    "#     class_name=\"Datasource\",\n",
    "#     module_name=\"great_expectations.datasource\",\n",
    "#     batch_kwargs_generators={\n",
    "#         \"pandas_batch_generator\": {\n",
    "#             \"class_name\": \"SubdirReaderBatchKwargsGenerator\",\n",
    "#             \"base_directory\": \"path/to/your/csv/directory\"\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# Step 5: Create or Load Expectation Suite\n",
    "# Here, we create a new expectation suite if it does not exist\n",
    "suite_name = \"sample_suite\"\n",
    "try:\n",
    "    suite = context.get_expectation_suite(suite_name)\n",
    "except ValueError:\n",
    "    suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "\n",
    "# Step 6: Create a Validator\n",
    "batch = context.get_batch({\n",
    "    \"datasource_name\": \"my_pandas_datasource\",  # Adjust as necessary\n",
    "    \"batch_kwargs\": {\n",
    "        \"path\": \"sample_data.csv\",  # Path to your CSV\n",
    "        \"reader_options\": {\"delimiter\": \",\"}\n",
    "    },\n",
    "    \"expectation_suite_name\": suite_name\n",
    "})\n",
    "validator = context.get_validator(batch)\n",
    "\n",
    "# Step 7: Add Expectations\n",
    "\n",
    "# Expecting the column \"name\" to exist\n",
    "validator.expect_column_to_exist(\"name\")\n",
    "\n",
    "# Expecting the column \"email\" to exist\n",
    "validator.expect_column_to_exist(\"email\")\n",
    "\n",
    "# Expecting the column \"age\" to be of type int64\n",
    "validator.expect_column_values_to_be_of_type(\"age\", \"int64\")\n",
    "\n",
    "# Expecting the column \"email\" to not have any null values\n",
    "validator.expect_column_values_to_not_be_null(\"email\")\n",
    "\n",
    "# Expecting the email format to match regex (basic email pattern)\n",
    "validator.expect_column_values_to_match_like(\n",
    "    \"email\", r\"^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$\"\n",
    ")\n",
    "\n",
    "# Step 8: Save the Expectations to the Suite\n",
    "validator.save_expectation_suite()\n",
    "\n",
    "# Step 9: Validate the Data (Generate a Validation Report)\n",
    "\n",
    "# Create a checkpoint (this is similar to running a checkpoint via CLI)\n",
    "checkpoint_config = {\n",
    "    \"name\": \"my_checkpoint\",\n",
    "    \"class_name\": \"Checkpoint\",\n",
    "    \"module_name\": \"great_expectations.checkpoint\",\n",
    "    \"batch_request\": {\n",
    "        \"datasource_name\": \"my_pandas_datasource\",\n",
    "        \"batch_kwargs\": {\n",
    "            \"path\": \"sample_data.csv\",  # Path to your CSV\n",
    "            \"reader_options\": {\"delimiter\": \",\"}\n",
    "        },\n",
    "        \"expectation_suite_name\": suite_name\n",
    "    }\n",
    "}\n",
    "\n",
    "# Run the checkpoint validation\n",
    "checkpoint = context.add_checkpoint(**checkpoint_config)\n",
    "result = checkpoint.run()\n",
    "print(\"Checkpoint validation result:\")\n",
    "print(result)\n",
    "\n",
    "# Step 10: View the Validation Results\n",
    "# Great Expectations generates data docs that can be opened in a browser\n",
    "# Open the generated docs in your browser to view the results\n",
    "context.build_data_docs()\n",
    "print(\"Validation results saved to data docs at:\")\n",
    "print(context.get_docs_sites())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Validate Datasets and Generate Reports\n",
    "\n",
    "1. Objective: Validate a dataset against defined expectations and generate a report.\n",
    "2. Steps:\n",
    "    - Execute the validation process on the dataset.\n",
    "    - Review the validation results and generate a report.\n",
    "    - Eg., Validate completeness and consistency expectations, and view the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExpectationSuite, ExpectationResult\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munittest\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context import DataContext\n",
    "from great_expectations.core import ExpectationSuite, ExpectationResult\n",
    "import unittest\n",
    "\n",
    "# Setup Great Expectations DataContext\n",
    "def setup_data_context():\n",
    "    try:\n",
    "        # Initialize the Great Expectations DataContext\n",
    "        context = DataContext(\"/path/to/great_expectations/directory\")\n",
    "        return context\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing Great Expectations DataContext: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load dataset with error handling\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "        return None\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"Error: The file {file_path} is empty.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred while loading the file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Define basic expectations for the dataset\n",
    "def create_expectations(df):\n",
    "    # Expectation 1: Check if the columns exist\n",
    "    if 'customer_id' not in df.columns:\n",
    "        print(\"Error: 'customer_id' column is missing.\")\n",
    "    else:\n",
    "        print(\"'customer_id' column is present.\")\n",
    "\n",
    "    # Expectation 2: Check if customer_id is unique\n",
    "    if df['customer_id'].duplicated().any():\n",
    "        print(\"Error: 'customer_id' column contains duplicates.\")\n",
    "    else:\n",
    "        print(\"'customer_id' column is unique.\")\n",
    "\n",
    "    # Expectation 3: Check if the data types are as expected\n",
    "    expected_dtypes = {\n",
    "        'customer_id': 'int64',\n",
    "        'age': 'float64',\n",
    "        'gender': 'object'\n",
    "    }\n",
    "    \n",
    "    for column, dtype in expected_dtypes.items():\n",
    "        if column in df.columns and df[column].dtype != dtype:\n",
    "            print(f\"Error: '{column}' is not of type {dtype}.\")\n",
    "        else:\n",
    "            print(f\"'{column}' has the expected data type {dtype}.\")\n",
    "\n",
    "# Create a function to validate data completeness\n",
    "def validate_completeness(df):\n",
    "    # Expectation: Ensure that no more than 10% of any column's values are missing\n",
    "    for column in df.columns:\n",
    "        missing_percent = df[column].isnull().sum() / len(df) * 100\n",
    "        if missing_percent > 10:\n",
    "            print(f\"Warning: '{column}' has more than 10% missing data.\")\n",
    "        else:\n",
    "            print(f\"'{column}' completeness is within acceptable limits.\")\n",
    "\n",
    "# Create a function to validate data accuracy\n",
    "def validate_accuracy(df):\n",
    "    # Example: Validate that 'age' column values are non-negative\n",
    "    if (df['age'] < 0).any():\n",
    "        print(\"Error: 'age' column contains negative values.\")\n",
    "    else:\n",
    "        print(\"'age' column contains valid values.\")\n",
    "\n",
    "# Unit Tests to validate the expectations\n",
    "class TestDataQuality(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.df = load_data(\"sample_data.csv\")\n",
    "        \n",
    "    def test_completeness(self):\n",
    "        # Ensure no column has more than 10% missing data\n",
    "        for column in self.df.columns:\n",
    "            missing_percent = self.df[column].isnull().sum() / len(self.df) * 100\n",
    "            self.assertLessEqual(missing_percent, 10, f\"{column} has more than 10% missing data.\")\n",
    "    \n",
    "    def test_column_presence(self):\n",
    "        required_columns = ['customer_id', 'age', 'gender']\n",
    "        for column in required_columns:\n",
    "            self.assertIn(column, self.df.columns, f\"{column} is missing from the dataset.\")\n",
    "    \n",
    "    def test_data_types(self):\n",
    "        expected_dtypes = {\n",
    "            'customer_id': 'int64',\n",
    "            'age': 'float64',\n",
    "            'gender': 'object'\n",
    "        }\n",
    "        for column, dtype in expected_dtypes.items():\n",
    "            self.assertEqual(self.df[column].dtype, dtype, f\"{column} does not have the expected data type.\")\n",
    "\n",
    "# Main process\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the dataset\n",
    "    df = load_data(\"sample_data.csv\")\n",
    "    if df is not None:\n",
    "        # Setup Great Expectations\n",
    "        context = setup_data_context()\n",
    "        if context is not None:\n",
    "            create_expectations(df)\n",
    "            validate_completeness(df)\n",
    "            validate_accuracy(df)\n",
    "        \n",
    "        # Run the unit tests\n",
    "        unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Advanced Expectations and Scheduling\n",
    "\n",
    "1. Objective: Create advanced expectations for conditional checks and automate the validation.\n",
    "2. Steps:\n",
    "    - Define advanced expectations based on complex conditions.\n",
    "    - Use scheduling tools to automate periodic checks.\n",
    "    - E.g., an expectation that customer IDs must be unique and schedule a daily check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code from here\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Importing necessary libraries\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Step 1: Load the Sample Dataset (same as before)\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "# Importing necessary libraries\n",
    "import great_expectations as ge\n",
    "from great_expectations.data_context import DataContext\n",
    "\n",
    "# Step 1: Load the Sample Dataset (same as before)\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"sample_data.csv\")\n",
    "print(\"Sample Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Initialize Great Expectations Context\n",
    "context = DataContext()\n",
    "\n",
    "# Step 3: Load the Existing Expectation Suite\n",
    "suite_name = \"sample_suite\"\n",
    "try:\n",
    "    suite = context.get_expectation_suite(suite_name)\n",
    "except ValueError:\n",
    "    print(f\"Expectation suite '{suite_name}' not found. Please create it first.\")\n",
    "    exit()\n",
    "\n",
    "# Step 4: Setup Batch for Validation\n",
    "batch_kwargs = {\n",
    "    \"path\": \"sample_data.csv\",  # Path to your CSV\n",
    "    \"reader_options\": {\"delimiter\": \",\"}\n",
    "}\n",
    "batch_request = {\n",
    "    \"datasource_name\": \"my_pandas_datasource\",  # Adjust as necessary based on your datasource\n",
    "    \"batch_kwargs\": batch_kwargs,\n",
    "    \"expectation_suite_name\": suite_name\n",
    "}\n",
    "batch = context.get_batch(batch_request)\n",
    "\n",
    "# Step 5: Create Validator for the Dataset\n",
    "validator = context.get_validator(batch)\n",
    "\n",
    "# Step 6: Run the Validation\n",
    "validation_result = validator.validate()\n",
    "\n",
    "# Step 7: Review the Validation Results\n",
    "print(\"Validation Results:\")\n",
    "print(validation_result)\n",
    "\n",
    "# Step 8: Generate Data Docs (HTML report)\n",
    "context.build_data_docs()\n",
    "\n",
    "# Step 9: Open the Data Docs folder (This will generate a visual report in the browser)\n",
    "docs_path = context.get_docs_sites()\n",
    "print(f\"Data docs available at: {docs_path}\")\n",
    "\n",
    "# Step 10: Optional - Save the Report (This generates a static HTML report)\n",
    "# You can specify a location to save the report for offline access\n",
    "# context.open_data_docs()  # Opens the docs in the browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mge\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mapscheduler\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschedulers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblocking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BlockingScheduler\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataContext' from 'great_expectations.data_context' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/data_context/__init__.py)"
     ]
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "from great_expectations.data_context import DataContext\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the Sample Dataset (same as before)\n",
    "df = pd.read_csv(\"sample_data.csv\")\n",
    "print(\"Sample Data:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Initialize Great Expectations Context\n",
    "context = DataContext()\n",
    "\n",
    "# Step 3: Load/Create an Expectation Suite\n",
    "suite_name = \"advanced_suite\"\n",
    "try:\n",
    "    suite = context.get_expectation_suite(suite_name)\n",
    "except ValueError:\n",
    "    suite = context.create_expectation_suite(suite_name, overwrite_existing=True)\n",
    "\n",
    "# Step 4: Create a Batch Request\n",
    "batch_kwargs = {\n",
    "    \"path\": \"sample_data.csv\",  # Path to your CSV\n",
    "    \"reader_options\": {\"delimiter\": \",\"}\n",
    "}\n",
    "batch_request = {\n",
    "    \"datasource_name\": \"my_pandas_datasource\",  # Adjust as necessary based on your datasource\n",
    "    \"batch_kwargs\": batch_kwargs,\n",
    "    \"expectation_suite_name\": suite_name\n",
    "}\n",
    "batch = context.get_batch(batch_request)\n",
    "\n",
    "# Step 5: Create a Validator for the Dataset\n",
    "validator = context.get_validator(batch)\n",
    "\n",
    "# Step 6: Define Advanced Expectations\n",
    "\n",
    "# Expecting that the 'customer_id' column should have unique values\n",
    "validator.expect_column_values_to_be_unique(\"customer_id\")\n",
    "\n",
    "# Expecting 'age' to be between 18 and 100\n",
    "validator.expect_column_value_lengths_to_be_between(\"age\", min_value=18, max_value=100)\n",
    "\n",
    "# Adding the expectations to the suite\n",
    "validator.save_expectation_suite()\n",
    "\n",
    "# Step 7: Run the Validation\n",
    "\n",
    "def validate_data():\n",
    "    validation_result = validator.validate()\n",
    "    print(\"Validation Results:\")\n",
    "    print(validation_result)\n",
    "\n",
    "    # Step 8: Build Data Docs (Report)\n",
    "    context.build_data_docs()\n",
    "    docs_path = context.get_docs_sites()\n",
    "    print(f\"Data docs available at: {docs_path}\")\n",
    "\n",
    "# Step 9: Schedule the Validation with APScheduler (automated daily check)\n",
    "\n",
    "scheduler = BlockingScheduler()\n",
    "\n",
    "# Add the scheduled job for daily validation at a specific time (e.g., 8:00 AM every day)\n",
    "scheduler.add_job(validate_data, 'interval', hours=24, start_date='2025-05-13 08:00:00')\n",
    "\n",
    "print(\"Scheduled job added to run daily for data validation.\")\n",
    "\n",
    "# Start the scheduler (this will keep running indefinitely)\n",
    "scheduler.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'DataContext' from 'great_expectations.core' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/core/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataContext\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgreat_expectations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_context\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m(great_expectations\u001b[38;5;241m.\u001b[39mdata_context))\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'DataContext' from 'great_expectations.core' (/home/vscode/.local/lib/python3.10/site-packages/great_expectations/core/__init__.py)"
     ]
    }
   ],
   "source": [
    "from great_expectations.core import DataContext\n",
    "import great_expectations.data_context\n",
    "print(dir(great_expectations.data_context))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
