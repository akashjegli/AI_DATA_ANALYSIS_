{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AI/ML â€“ Improving Model Performance with Clean Data\n",
    "\n",
    "**Task 1**: Data Preprocessing for Models\n",
    "\n",
    "**Objective**: Enhance data quality for better AI/ML outcomes.\n",
    "\n",
    "**Steps**:\n",
    "1. Choose a dataset for training an AI/ML model.\n",
    "2. Identify common data issues like null values, redundant features, or noisydata.\n",
    "3. Apply preprocessing methods such as imputation, normalization, or feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'sample_transactions.csv' created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data for transactions\n",
    "data = {\n",
    "    'transaction_id': [101, 102, 103, 104, 105, 106],\n",
    "    'transaction_amount': [250.75, 500.10, 150.00, np.nan, 1200.50, 300.00],\n",
    "    'customer_age': [25, 34, 28, 45, 31, 22],\n",
    "    'transaction_date': ['2025-05-01', '2025-05-02', '2025-05-03', '2025-05-04', '2025-05-05', '2025-05-06'],\n",
    "    'status': ['completed', 'completed', 'failed', 'completed', 'completed', 'failed']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv('sample_transactions.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'sample_transactions.csv' created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**: Evaluate Model Performance\n",
    "\n",
    "**Objective**: Assess the impact of data quality improvements on model performance.\n",
    "\n",
    "**Steps**:\n",
    "1. Train a simple ML model with and without preprocessing.\n",
    "2. Analyze and compare model performance metrics to evaluate the impact of data quality strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame:\n",
      "    transaction_id  transaction_amount  customer_age transaction_date  \\\n",
      "0        -1.46385           -0.665635     -0.785575       2025-05-01   \n",
      "1        -0.87831            0.057509      0.426455       2025-05-02   \n",
      "2        -0.29277           -0.957821     -0.381565       2025-05-03   \n",
      "3         0.29277            0.000000      1.907826       2025-05-04   \n",
      "4         0.87831            2.088750      0.022445       2025-05-05   \n",
      "5         1.46385           -0.522804     -1.189585       2025-05-06   \n",
      "\n",
      "      status  transaction_per_age  \n",
      "0  completed             0.847321  \n",
      "1  completed             0.134854  \n",
      "2     failed             2.510243  \n",
      "3  completed             0.000000  \n",
      "4  completed            93.060801  \n",
      "5     failed             0.439484  \n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Sample data for transactions\n",
    "data = {\n",
    "    'transaction_id': [101, 102, 103, 104, 105, 106],\n",
    "    'transaction_amount': [250.75, 500.10, 150.00, np.nan, 1200.50, 300.00],\n",
    "    'customer_age': [25, 34, 28, 45, 31, 22],\n",
    "    'transaction_date': ['2025-05-01', '2025-05-02', '2025-05-03', '2025-05-04', '2025-05-05', '2025-05-06'],\n",
    "    'status': ['completed', 'completed', 'failed', 'completed', 'completed', 'failed']\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Identify numerical columns for imputation\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Step 2: Handle missing values (Imputation only on numerical columns)\n",
    "imputer = SimpleImputer(strategy='mean')  # Imputing missing values with the mean\n",
    "df[numerical_columns] = imputer.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Step 3: Normalize the numerical columns (Standardization)\n",
    "scaler = StandardScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Step 4: Feature Engineering (Example: Create a new feature from existing ones)\n",
    "df['transaction_per_age'] = df['transaction_amount'] / df['customer_age']\n",
    "\n",
    "# Check the processed data\n",
    "print(\"Processed DataFrame:\\n\", df)\n",
    "\n",
    "# Save processed data to a new CSV file\n",
    "df.to_csv('processed_transactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.12499952036502948\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Sample data for transactions\n",
    "data = {\n",
    "    'transaction_id': [101, 102, 103, 104, 105, 106],\n",
    "    'transaction_amount': [250.75, 500.10, 150.00, None, 1200.50, 300.00],\n",
    "    'customer_age': [25, 34, 28, 45, 31, 22],\n",
    "    'transaction_date': ['2025-05-01', '2025-05-02', '2025-05-03', '2025-05-04', '2025-05-05', '2025-05-06'],\n",
    "    'status': ['completed', 'completed', 'failed', 'completed', 'completed', 'failed']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Step 1: Handle missing values (Imputation on numerical columns only)\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputer = SimpleImputer(strategy='mean')  # Impute missing values with the mean\n",
    "df[numerical_columns] = imputer.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Step 2: Normalize the numerical columns (Standardization)\n",
    "scaler = StandardScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Step 3: Feature Engineering (Example: Create a new feature from existing ones)\n",
    "df['transaction_per_age'] = df['transaction_amount'] / df['customer_age']\n",
    "\n",
    "# Assume 'transaction_amount' is the target column you want to predict\n",
    "# Replace 'target_column' with the actual name of your target column in your data\n",
    "target_column = 'transaction_amount'\n",
    "\n",
    "# Step 4: Split data into training and testing sets\n",
    "X = df.drop(columns=[target_column, 'transaction_id', 'transaction_date', 'status'])  # Features (drop non-predictive columns)\n",
    "y = df[target_column]  # Target variable (transaction amount)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Train a model (e.g., Linear Regression)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Predict and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 7: Calculate Mean Squared Error for model evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE without preprocessing: 26742.930732130044\n",
      "MSE with preprocessing: 0.22492599498537885\n",
      "\n",
      "Data preprocessing improved model performance!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Sample data for transactions\n",
    "data = {\n",
    "    'transaction_id': [101, 102, 103, 104, 105, 106],\n",
    "    'transaction_amount': [250.75, 500.10, 150.00, None, 1200.50, 300.00],\n",
    "    'customer_age': [25, 34, 28, 45, 31, 22],\n",
    "    'transaction_date': ['2025-05-01', '2025-05-02', '2025-05-03', '2025-05-04', '2025-05-05', '2025-05-06'],\n",
    "    'status': ['completed', 'completed', 'failed', 'completed', 'completed', 'failed']\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Handle missing values in the target column ('transaction_amount')\n",
    "df['transaction_amount'].fillna(df['transaction_amount'].mean(), inplace=True)\n",
    "\n",
    "# Step 1: Split data into training and testing sets\n",
    "X = df.drop(columns=['transaction_amount', 'transaction_id', 'transaction_date', 'status'])  # Features\n",
    "y = df['transaction_amount']  # Target variable (transaction amount)\n",
    "\n",
    "# Check if there are any NaN values in the target column (y)\n",
    "if y.isnull().any():\n",
    "    print(\"Warning: Missing values found in target column. Filling with mean.\")\n",
    "    y.fillna(y.mean(), inplace=True)\n",
    "\n",
    "# Ensure the features (X) have no missing values\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train model without preprocessing\n",
    "def train_model_without_preprocessing(X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "# Step 2: Train model without preprocessing\n",
    "mse_without_preprocessing = train_model_without_preprocessing(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Step 3: Preprocess the data (Imputation and Normalization)\n",
    "# Handle missing values (Imputation on numerical columns only)\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputer = SimpleImputer(strategy='mean')  # Impute missing values with the mean\n",
    "df[numerical_columns] = imputer.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Normalize the numerical columns (Standardization)\n",
    "scaler = StandardScaler()\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "# Recreate the train-test split after preprocessing\n",
    "X = df.drop(columns=['transaction_amount', 'transaction_id', 'transaction_date', 'status'])  # Features\n",
    "y = df['transaction_amount']  # Target variable (transaction amount)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to train model with preprocessing\n",
    "def train_model_with_preprocessing(X_train, X_test, y_train, y_test):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "# Step 4: Train model with preprocessing\n",
    "mse_with_preprocessing = train_model_with_preprocessing(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Step 5: Compare performance\n",
    "print(\"MSE without preprocessing:\", mse_without_preprocessing)\n",
    "print(\"MSE with preprocessing:\", mse_with_preprocessing)\n",
    "\n",
    "# Step 6: Conclusion based on comparison\n",
    "if mse_with_preprocessing < mse_without_preprocessing:\n",
    "    print(\"\\nData preprocessing improved model performance!\")\n",
    "else:\n",
    "    print(\"\\nData preprocessing did not improve model performance.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
