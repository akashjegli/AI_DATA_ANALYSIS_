{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SHAP for Feature Drift Analysis\n",
    "**Description**: Utilize SHapley Additive exPlanations (SHAP) values to analyze feature\n",
    "importance changes over time, indicating feature drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting shap\n",
      "  Downloading shap-0.47.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: numpy in /home/vscode/.local/lib/python3.10/site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/vscode/.local/lib/python3.10/site-packages (from shap) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn in /home/vscode/.local/lib/python3.10/site-packages (from shap) (1.6.1)\n",
      "Requirement already satisfied: pandas in /home/vscode/.local/lib/python3.10/site-packages (from shap) (2.1.4)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /home/vscode/.local/lib/python3.10/site-packages (from shap) (4.67.1)\n",
      "Requirement already satisfied: packaging>20.9 in /home/vscode/.local/lib/python3.10/site-packages (from shap) (25.0)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting numba>=0.54 (from shap)\n",
      "  Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting cloudpickle (from shap)\n",
      "  Downloading cloudpickle-3.1.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/vscode/.local/lib/python3.10/site-packages (from shap) (4.13.2)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.54->shap)\n",
      "  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/vscode/.local/lib/python3.10/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vscode/.local/lib/python3.10/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/vscode/.local/lib/python3.10/site-packages (from pandas->shap) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/vscode/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/vscode/.local/lib/python3.10/site-packages (from scikit-learn->shap) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/vscode/.local/lib/python3.10/site-packages (from scikit-learn->shap) (3.6.0)\n",
      "Downloading shap-0.47.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (992 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m992.3/992.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Downloading numba-0.61.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: slicer, llvmlite, cloudpickle, numba, shap\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [shap][32m4/5\u001b[0m [shap]]ickle]\n",
      "\u001b[1A\u001b[2KSuccessfully installed cloudpickle-3.1.1 llvmlite-0.44.0 numba-0.61.2 shap-0.47.2 slicer-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "def generate_data():\n",
    "    np.random.seed(42)\n",
    "    train_df = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0, 1, 1000),\n",
    "        'feature2': np.random.normal(5, 1, 1000),\n",
    "        'feature3': np.random.randint(0, 2, 1000),\n",
    "        'label': np.random.randint(0, 2, 1000)\n",
    "    })\n",
    "    test_df = pd.DataFrame({\n",
    "        'feature1': np.random.normal(0.5, 1, 1000),\n",
    "        'feature2': np.random.normal(6, 1, 1000),\n",
    "        'feature3': np.random.randint(0, 2, 1000),\n",
    "        'label': np.random.randint(0, 2, 1000)\n",
    "    })\n",
    "    return train_df, test_df\n",
    "\n",
    "def validate_data(train_df, test_df):\n",
    "    if train_df.empty or test_df.empty:\n",
    "        raise ValueError(\"One or both input DataFrames are empty.\")\n",
    "    required_columns = {'feature1', 'feature2', 'feature3', 'label'}\n",
    "    if not required_columns.issubset(train_df.columns) or not required_columns.issubset(test_df.columns):\n",
    "        raise ValueError(\"Missing required columns in input data.\")\n",
    "\n",
    "def analyze_shap_drift(train_df, test_df):\n",
    "    try:\n",
    "        validate_data(train_df, test_df)\n",
    "\n",
    "        X_train = train_df.drop(columns=['label'])\n",
    "        y_train = train_df['label']\n",
    "        X_test = test_df.drop(columns=['label'])\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "\n",
    "        shap_values_train = explainer.shap_values(X_train)[1]\n",
    "        shap_values_test = explainer.shap_values(X_test)[1]\n",
    "\n",
    "        mean_train = np.abs(shap_values_train).mean(axis=0)\n",
    "        mean_test = np.abs(shap_values_test).mean(axis=0)\n",
    "\n",
    "        shap_df = pd.DataFrame({\n",
    "            'feature': X_train.columns,\n",
    "            'mean_abs_shap_train': mean_train,\n",
    "            'mean_abs_shap_test': mean_test,\n",
    "            'shap_diff': np.abs(mean_train - mean_test)\n",
    "        }).sort_values('shap_diff', ascending=False)\n",
    "\n",
    "        return shap_df\n",
    "\n",
    "    except NotFittedError:\n",
    "        raise RuntimeError(\"Model training failed.\")\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"SHAP analysis failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_shap_drift(shap_df):\n",
    "    try:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        index = np.arange(len(shap_df))\n",
    "        bar_width = 0.35\n",
    "\n",
    "        plt.bar(index, shap_df['mean_abs_shap_train'], bar_width, label='Train SHAP')\n",
    "        plt.bar(index + bar_width, shap_df['mean_abs_shap_test'], bar_width, label='Test SHAP')\n",
    "\n",
    "        plt.xlabel('Features')\n",
    "        plt.ylabel('Mean |SHAP| Value')\n",
    "        plt.title('SHAP Feature Drift Analysis')\n",
    "        plt.xticks(index + bar_width / 2, shap_df['feature'], rotation=45)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Plotting failed: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...E\n",
      "======================================================================\n",
      "ERROR: test_shap_analysis_output (__main__.TestShapDrift)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6825/736230695.py\", line 50, in analyze_shap_drift\n",
      "    shap_df = pd.DataFrame({\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/pandas/core/frame.py\", line 733, in __init__\n",
      "    mgr = dict_to_mgr(data, index, columns, dtype=dtype, copy=copy, typ=manager)\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py\", line 503, in dict_to_mgr\n",
      "    return arrays_to_mgr(arrays, columns, index, dtype=dtype, typ=typ, consolidate=copy)\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py\", line 114, in arrays_to_mgr\n",
      "    index = _extract_index(arrays)\n",
      "  File \"/home/vscode/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py\", line 677, in _extract_index\n",
      "    raise ValueError(\"All arrays must be of the same length\")\n",
      "ValueError: All arrays must be of the same length\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_6825/1406611350.py\", line 23, in test_shap_analysis_output\n",
      "    shap_df = analyze_shap_drift(self.train_df, self.test_df)\n",
      "  File \"/tmp/ipykernel_6825/736230695.py\", line 62, in analyze_shap_drift\n",
      "    raise RuntimeError(f\"SHAP analysis failed: {str(e)}\")\n",
      "RuntimeError: SHAP analysis failed: All arrays must be of the same length\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 5.725s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class TestShapDrift(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.train_df, self.test_df = generate_data()\n",
    "\n",
    "    def test_data_validation_success(self):\n",
    "        try:\n",
    "            validate_data(self.train_df, self.test_df)\n",
    "        except Exception:\n",
    "            self.fail(\"validate_data() raised Exception unexpectedly!\")\n",
    "\n",
    "    def test_empty_data(self):\n",
    "        with self.assertRaises(ValueError):\n",
    "            validate_data(pd.DataFrame(), pd.DataFrame())\n",
    "\n",
    "    def test_missing_columns(self):\n",
    "        df = pd.DataFrame({'a': [1], 'b': [2]})\n",
    "        with self.assertRaises(ValueError):\n",
    "            validate_data(df, df)\n",
    "\n",
    "    def test_shap_analysis_output(self):\n",
    "        shap_df = analyze_shap_drift(self.train_df, self.test_df)\n",
    "        self.assertFalse(shap_df.empty)\n",
    "        self.assertIn('shap_diff', shap_df.columns)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
