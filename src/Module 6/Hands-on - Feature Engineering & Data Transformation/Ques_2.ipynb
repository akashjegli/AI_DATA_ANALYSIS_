{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'customer_data.csv' created successfully.\n",
      "Original DataFrame:\n",
      "   Age  Annual_Income Region\n",
      "0   25          40000   East\n",
      "1   30          50000   West\n",
      "2   35          60000  North\n",
      "3   40          70000  South\n",
      "4   45          80000   East\n",
      "\n",
      "Transformed DataFrame:\n",
      "        Age  Annual_Income  Region_East  Region_North  Region_South  \\\n",
      "0  0.000000       0.000000         True         False         False   \n",
      "1  0.111111       0.111111        False         False         False   \n",
      "2  0.222222       0.222222        False          True         False   \n",
      "3  0.333333       0.333333        False         False          True   \n",
      "4  0.444444       0.444444         True         False         False   \n",
      "\n",
      "   Region_West  \n",
      "0        False  \n",
      "1         True  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False  \n",
      "\n",
      "Summary Statistics after Scaling:\n",
      "             Age  Annual_Income\n",
      "count  10.000000      10.000000\n",
      "mean    0.500000       0.500000\n",
      "std     0.336406       0.336406\n",
      "min     0.000000       0.000000\n",
      "25%     0.250000       0.250000\n",
      "50%     0.500000       0.500000\n",
      "75%     0.750000       0.750000\n",
      "max     1.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling & Encoding\n",
    "\n",
    "# Objective: Learn to scale numerical features and encode categorical features for better model performance.\n",
    "# Instructions:\n",
    "# For each example, perform the following steps:\n",
    "#     1. Load the Dataset: Load the dataset into your environment.\n",
    "#     2. Feature Scaling: Apply scaling methods (StandardScaler or MinMaxScaler) to specified numerical columns.\n",
    "#     3. Feature Encoding: Apply encoding methods (One-Hot Encoding or Label Encoding) to specified categorical columns.\n",
    "#     4. Verify Changes: Check the data to ensure proper scaling and encoding. \n",
    "\n",
    "\n",
    "# Task:\n",
    "#     Dataset: customer_data.csv (get it by your own it includes the columns of Age , Annual_Income)\n",
    "#     Columns to scale: Age , Annual_Income\n",
    "#     Column to encode: Region\n",
    "#     Steps:\n",
    "#         1. Load customer_data.csv .\n",
    "#         2. Use MinMaxScaler on Age and Annual_Income .\n",
    "#         3. Perform One-Hot Encoding on Region .\n",
    "#         4. Verify by assessing the transformed dataset.\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create the sample dataset\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    'Annual_Income': [40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000],\n",
    "    'Region': ['East', 'West', 'North', 'South', 'East', 'West', 'North', 'South', 'East', 'West']\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('customer_data.csv', index=False)\n",
    "\n",
    "print(\"CSV file 'customer_data.csv' created successfully.\")\n",
    "\n",
    "# Task:\n",
    "#     Dataset: customer_data.csv (get it by your own it includes the columns of Age , Annual_Income)\n",
    "#     Columns to scale: Age , Annual_Income\n",
    "#     Column to encode: Region\n",
    "#     Steps:\n",
    "#         1. Load customer_data.csv .\n",
    "#         2. Use MinMaxScaler on Age and Annual_Income .\n",
    "#         3. Perform One-Hot Encoding on Region .\n",
    "#         4. Verify by assessing the transformed dataset.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('customer_data.csv')\n",
    "\n",
    "# Display the first few rows of the dataset to inspect it\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.head())\n",
    "\n",
    "# Step 2: Apply MinMaxScaler on Age and Annual_Income columns\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply the scaler to the specified columns\n",
    "df[['Age', 'Annual_Income']] = scaler.fit_transform(df[['Age', 'Annual_Income']])\n",
    "\n",
    "# Step 3: Apply One-Hot Encoding on Region column\n",
    "# Use pandas get_dummies to perform One-Hot Encoding\n",
    "df_encoded = pd.get_dummies(df, columns=['Region'], drop_first=False)\n",
    "\n",
    "# Step 4: Verify the changes by inspecting the transformed dataset\n",
    "print(\"\\nTransformed DataFrame:\")\n",
    "print(df_encoded.head())\n",
    "\n",
    "# Optionally, display summary statistics to verify scaling\n",
    "print(\"\\nSummary Statistics after Scaling:\")\n",
    "print(df_encoded[['Age', 'Annual_Income']].describe())    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
